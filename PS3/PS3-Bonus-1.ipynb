{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import io_backend as io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IO Aware #1\n",
    "=============\n",
    "\n",
    "\n",
    "### Instructions / Notes:\n",
    "\n",
    "**_Read these carefully_**\n",
    "\n",
    "* **Be sure to use the latest `io_backend.py` file released with this activity**\n",
    "* **RECOMMENDED: ONLY USE ONE D3 DISPLAY WINDOW AT A TIME; CLEAR THE OUTPUT (\"Cell >> Current Output >> Clear\") of all ones not being used!**\n",
    "* Note that support for the visualization tools herein is somewhat more limited- however we still welcome your feedback on bugs, suggestions for improvement, etc!\n",
    "* **See Piazza for submission instructions**\n",
    "* _Have fun!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 1: Aware.io\n",
    "\n",
    "**_[10 points]_**\n",
    "\n",
    "Your startup, Aware.io, has hired a new employee named Hipster Doofus, who prefers to go by \"HD\".  HD implements the following algorithm to find duplicates, over a very simple set of single-attribute relations (i.e. the join returns pairs of tuples with the same value).  Can you improve it to have better performance?  And what is your new version commonly called (HINT: It should be one of the ones we covered in lecture!)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tuple_nested_loop_join(b, fid1, fid2):\n",
    "    P = b.page_size\n",
    "    \n",
    "    # A FileIterator object will get the next element from the next\n",
    "    # page in a file\n",
    "    fi1 = io.FileIterator(b, fid1)\n",
    "    \n",
    "    # Loop through the r values\n",
    "    for r in fi1:\n",
    "        \n",
    "        # Loop through the s values\n",
    "        fi2 = io.FileIterator(b, fid2)\n",
    "        for s in fi2:\n",
    "            if r == s:\n",
    "                print 'Duplicate found: %s' % r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we specify that each page has 2 values, and the buffer has 3 pages\n",
    "# NOTE: Your algorithm should work for general page / buffer sizes- you should play around with these values!\n",
    "b = io.Buffer(page_size=2, buffer_size=3)\n",
    "\n",
    "# Create two unsorted files of L random integer values from range(0,R)\n",
    "# Where here L=8, R=10\n",
    "fid1 = io.new_rand_file(b, 10, 8, sorted=False)\n",
    "fid2 = io.new_rand_file(b, 10, 8, sorted=False)\n",
    "\n",
    "# Set the starting point for any animations here, to skip the setup part\n",
    "b.display_set_mark()\n",
    "\n",
    "# Merge the files!\n",
    "tuple_nested_loop_join(b, fid1, fid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.display(speed=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
